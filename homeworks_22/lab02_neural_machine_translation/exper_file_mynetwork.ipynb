{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "681a20fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchtext\n",
    "from torchtext.legacy.datasets import TranslationDataset, Multi30k\n",
    "from torchtext.legacy.data import Field, BucketIterator\n",
    "\n",
    "import spacy\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'figure.figsize': (16, 12), 'font.size': 14})\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from subword_nmt.learn_bpe import learn_bpe\n",
    "from subword_nmt.apply_bpe import BPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc4d67de",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_W = WordPunctTokenizer()\n",
    "def tokenize(x, tokenizer=tokenizer_W):\n",
    "    return tokenizer.tokenize(x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcfcfff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_do_data = '../datasets/Machine_translation_EN_RU/data_small.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1853594",
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = Field(tokenize=tokenize,\n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)\n",
    "\n",
    "TRG = Field(tokenize=tokenize,\n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)\n",
    "\n",
    "dataset = torchtext.legacy.data.TabularDataset(\n",
    "    path=path_do_data,\n",
    "    format='tsv',\n",
    "    fields=[('trg', TRG), ('src', SRC)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6019c369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['отель', 'cala', 'ferrera', 'находится', 'в', '44', 'км', 'от', 'курортного', 'поселка', 'эль', '-', 'ареналя', 'и', 'в', '46', 'км', 'от', 'курортного', 'поселка', 'плайя', '-', 'де', '-', 'пальмы', '.']\n",
      "['el', 'arenal', 'is', '44', 'km', 'from', 'hotel', 'cala', 'ferrera', ',', 'while', 'playa', 'de', 'palma', 'is', '46', 'km', 'from', 'the', 'property', '.']\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data, test_data = dataset.split(split_ratio=[0.8, 0.15, 0.05])\n",
    "print(train_data[0].src)\n",
    "print(train_data[0].trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3eeafdd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 4000\n",
      "Number of validation examples: 250\n",
      "Number of testing examples: 750\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
    "print(f\"Number of testing examples: {len(test_data.examples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "205c50f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (ru) vocabulary: 1889\n",
      "Unique tokens in target (en) vocabulary: 1439\n"
     ]
    }
   ],
   "source": [
    "SRC.build_vocab(train_data, min_freq = 3)\n",
    "TRG.build_vocab(train_data, min_freq = 3)\n",
    "\n",
    "print(f\"Unique tokens in source (ru) vocabulary: {len(SRC.vocab)}\")\n",
    "print(f\"Unique tokens in target (en) vocabulary: {len(TRG.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ae0cb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'trg': ['if', 'you', 'feel', 'like', 'visiting', 'the', 'surroundings', ',', 'check', 'out', 'marari', 'beach', 'that', 'is', '25', 'km', 'and', 'the', 'karunakaran', 'musuem', 'that', 'is', '30', 'km', '.'], 'src': ['желающие', 'исследовать', 'окрестности', 'могут', 'посетить', 'пляж', 'марари', '(', 'в', '25', 'км', ')', 'и', 'музей', 'карунакаран', '(', 'в', '30', 'км', ').']}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6812443",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdc3e3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _len_sort_key(x):\n",
    "    return len(x.src)\n",
    "\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device,\n",
    "    sort_key=_len_sort_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "55b62b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([15, 2]), torch.Size([11, 2]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 8\n",
    "DEC_EMB_DIM = 8\n",
    "HID_DIM = 4\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "for x in train_iterator:\n",
    "    sample_src = x.src\n",
    "    sample_trg = x.trg\n",
    "    \n",
    "sample_src.shape, sample_trg.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29af9148",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "50b83c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_network\n",
    "Encoder = my_network.Encoder\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "766d6f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_hid, enc_cell = enc(sample_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2e5472f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 2]) torch.Size([2, 2, 4]) torch.Size([2, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "#hidden = [n layers * n directions, batch size, hid dim]\n",
    "#cell = [n layers * n directions, batch size, hid dim]\n",
    "print(sample_src.shape, enc_hid.shape, enc_cell.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8136e637",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c322363c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Decoder = my_network.Decoder\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "991691c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 2 1439\n"
     ]
    }
   ],
   "source": [
    "batch_size = sample_trg.shape[1]\n",
    "max_len = sample_trg.shape[0]\n",
    "trg_vocab_size = OUTPUT_DIM\n",
    "print(max_len, batch_size, trg_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "88229d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = torch.zeros(max_len, batch_size, trg_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d0a7b0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 4]) torch.Size([2, 2, 4])\n"
     ]
    }
   ],
   "source": [
    " #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
    "dec_hid, dec_cell = enc_hid, enc_cell\n",
    "print(dec_hid.shape, dec_cell.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1070779f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2])\n",
      "torch.Size([2])\n",
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "#first input to the decoder is the <sos> tokens\n",
    "input_ = sample_trg[0,:]\n",
    "print(input_)\n",
    "print(input_.shape)\n",
    "print(input_.unsqueeze(0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "82764fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(1, max_len):\n",
    "    #output = [batch size, output dim]\n",
    "        output, dec_hid, dec_cell = dec(input_, dec_hid, dec_cell)\n",
    "        outputs[t] = output\n",
    "        teacher_force = random.random() < 0.5\n",
    "        top1 = output.max(1)[1] # top1 is tensor of size [batch_size], [1] - returns indices\n",
    "        input_ = (sample_trg[t] if teacher_force else top1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8d3d929c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([0.8479, 0.6821], grad_fn=<MaxBackward0>),\n",
       "indices=tensor([900, 725]))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5d102ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([900, 725])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.max(1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "566fb76d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([11, 2, 1439]), torch.Size([10, 2, 1439]), torch.Size([20, 1439]))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape, outputs[1:].shape, outputs[1:].view(-1, outputs.shape[-1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bd21b64e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1439])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = outputs[1:].view(-1, \n",
    "                           outputs.shape[-1])\n",
    "#output = [(trg sent len - 1) * batch size, output dim]\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5d781c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 2]), torch.Size([20]))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_trg[1:].shape, sample_trg[1:].view(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1a0d2837",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = 1\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a128d86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_trg = sample_trg[1:].view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "abeeb350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.2299, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(outputs, sample_trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7715148f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20, 1439]), torch.Size([20]))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape, sample_trg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b159e50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
