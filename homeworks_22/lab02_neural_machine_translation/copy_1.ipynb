{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab assignment 02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Machine Translation in the wild\n",
    "In the third homework you are supposed to get the best translation you can for the EN-RU translation task.\n",
    "\n",
    "Basic approach using RNNs as encoder and decoder is implemented for you. \n",
    "\n",
    "Your ultimate task is to use the techniques we've covered, e.g.\n",
    "\n",
    "* Optimization enhancements (e.g. learning rate decay)\n",
    "\n",
    "* CNN encoder (with or without positional encoding)\n",
    "\n",
    "* attention/self-attention mechanism\n",
    "\n",
    "* pretraining the language model\n",
    "\n",
    "* [Byte Pair Encoding](https://github.com/rsennrich/subword-nmt)\n",
    "\n",
    "* or just fine-tunning BERT ;)\n",
    "\n",
    "to improve the translation quality. \n",
    "\n",
    "__Please use at least three different approaches/models and compare them (translation quality/complexity/training and evaluation time).__\n",
    "\n",
    "Write down some summary on your experiments and illustrate it with convergence plots/metrics and your thoughts. Just like you would approach a real problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting subword-nmt\n",
      "  Downloading subword_nmt-0.3.8-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\asus\\anaconda3\\lib\\site-packages (from subword-nmt) (4.50.2)\n",
      "Requirement already satisfied: mock in c:\\users\\asus\\anaconda3\\lib\\site-packages (from subword-nmt) (4.0.2)\n",
      "Installing collected packages: subword-nmt\n",
      "Successfully installed subword-nmt-0.3.8\n"
     ]
    }
   ],
   "source": [
    "# You might need to install the libraries below. Do it in the desired environment\n",
    "# if you are working locally.\n",
    "\n",
    "# !pip  install subword-nmt\n",
    "# ! pip install nltk\n",
    "# ! pip install torchtext"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# create small datatset\n",
    "with open('../datasets/Machine_translation_EN_RU/data.txt', 'r', encoding='utf8') as orig_file:\n",
    "    with open('../datasets/Machine_translation_EN_RU/data_small.txt', 'w', encoding='utf8') as small_file:\n",
    "        idx = 0\n",
    "        for line in orig_file:\n",
    "            idx += 1\n",
    "            if idx > 5_000:\n",
    "                break\n",
    "            else:\n",
    "                small_file.write(line)\n",
    "        "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Thanks to YSDA NLP course team for the data\n",
    "# (who thanks tilda and deephack teams for the data in their turn)\n",
    "\n",
    "import os\n",
    "path_do_data = '../datasets/Machine_translation_EN_RU/data.txt'\n",
    "if not os.path.exists(path_do_data):\n",
    "    print(\"Dataset not found locally. Downloading from github.\")\n",
    "    !wget https://raw.githubusercontent.com/neychev/made_nlp_course/master/datasets/Machine_translation_EN_RU/data.txt -nc\n",
    "    path_do_data = './data.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_do_data = '../datasets/Machine_translation_EN_RU/data_small.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchtext\n",
    "from torchtext.legacy.datasets import TranslationDataset, Multi30k\n",
    "from torchtext.legacy.data import Field, BucketIterator\n",
    "\n",
    "import spacy\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'figure.figsize': (16, 12), 'font.size': 14})\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from subword_nmt.learn_bpe import learn_bpe\n",
    "from subword_nmt.apply_bpe import BPE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main part\n",
    "__Here comes the preprocessing. Do not hesitate to use BPE or more complex preprocessing ;)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_W = WordPunctTokenizer()\n",
    "def tokenize(x, tokenizer=tokenizer_W):\n",
    "    return tokenizer.tokenize(x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi', '!', 'how', 'are', 'you', '?', 'i', 'don', \"'\", 't', 'know', 'where', 'you', 'were', '.']\n"
     ]
    }
   ],
   "source": [
    "ex_sentense = \"Hi! How are you? I don't know where you were.\"\n",
    "print(tokenize(ex_sentense))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = Field(tokenize=tokenize,\n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)\n",
    "\n",
    "TRG = Field(tokenize=tokenize,\n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)\n",
    "\n",
    "dataset = torchtext.legacy.data.TabularDataset(\n",
    "    path=path_do_data,\n",
    "    format='tsv',\n",
    "    fields=[('trg', TRG), ('src', SRC)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = dataset.split(split_ratio=[0.8, 0.15, 0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['в', 'нескольких', 'минутах', 'ходьбы', 'работает', 'несколько', 'кафе', ',', 'баров', 'и', 'ресторанов', '.']\n",
      "['several', 'café', 'bars', 'and', 'restaurants', 'can', 'be', 'found', 'within', 'short', 'walking', 'distance', '.']\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0].src)\n",
    "print(train_data[0].trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 4000\n",
      "Number of validation examples: 250\n",
      "Number of testing examples: 750\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
    "print(f\"Number of testing examples: {len(test_data.examples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC.build_vocab(train_data, min_freq = 3)\n",
    "TRG.build_vocab(train_data, min_freq = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (ru) vocabulary: 1882\n",
      "Unique tokens in target (en) vocabulary: 1441\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in source (ru) vocabulary: {len(SRC.vocab)}\")\n",
    "print(f\"Unique tokens in target (en) vocabulary: {len(TRG.vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are tokens from original (RU) corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>',\n",
       " 'видом',\n",
       " 'номере',\n",
       " 'заняться',\n",
       " 'проведения',\n",
       " 'открытой',\n",
       " 'которые',\n",
       " 'готовить',\n",
       " '32',\n",
       " 'ferienwohnung',\n",
       " 'телефон',\n",
       " 'машины',\n",
       " 'юнеско',\n",
       " 'искусства',\n",
       " 'сеансы',\n",
       " 'studio',\n",
       " 'езда',\n",
       " 'общих',\n",
       " 'самые']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SRC.vocab.itos[::100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And from target (EN) corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>',\n",
       " 'while',\n",
       " 'lounge',\n",
       " 'shopping',\n",
       " 'costa',\n",
       " 'light',\n",
       " 'library',\n",
       " 'downtown',\n",
       " 'golden',\n",
       " 'hospital',\n",
       " 'classically',\n",
       " 'single',\n",
       " 'carpeted',\n",
       " 'limited',\n",
       " 'super']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRG.vocab.itos[::100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is example from train dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'trg': ['it', 'offers', 'homemade', 'food', ',', 'free', 'wifi', 'and', 'rooms', 'with', 'sea', 'views', '.'], 'src': ['к', 'услугам', 'гостей', 'блюда', 'домашнего', 'приготовления', ',', 'бесплатный', 'wi', '-', 'fi', 'и', 'номера', 'с', 'видом', 'на', 'море', '.']}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[9]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the length distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length distribution in Train data\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "src_length = map(len, [vars(x)['src'] for x in train_data.examples])\n",
    "trg_length = map(len, [vars(x)['trg'] for x in train_data.examples])\n",
    "\n",
    "print('Length distribution in Train data')\n",
    "plt.figure(figsize=[8, 4])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"source length\")\n",
    "plt.hist(list(src_length), bins=20);\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"translation length\")\n",
    "plt.hist(list(trg_length), bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length distribution in Test data\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "src_length = map(len, [vars(x)['src'] for x in test_data.examples])\n",
    "trg_length = map(len, [vars(x)['trg'] for x in test_data.examples])\n",
    "\n",
    "print('Length distribution in Test data')\n",
    "plt.figure(figsize=[8, 4])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"source length\")\n",
    "plt.hist(list(src_length), bins=20);\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"translation length\")\n",
    "plt.hist(list(trg_length), bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model side\n",
    "__Here comes simple pipeline of NMT model learning. It almost copies the week03 practice__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _len_sort_key(x):\n",
    "    return len(x.src)\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device,\n",
    "    sort_key=_len_sort_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.legacy.data.batch.Batch of size 416]\n",
      "\t[.trg]:[torch.LongTensor of size 51x416]\n",
      "\t[.src]:[torch.LongTensor of size 55x416]\n",
      "torch.Size([55, 416]) torch.Size([51, 416])\n"
     ]
    }
   ],
   "source": [
    "for x in train_iterator:\n",
    "    break\n",
    "print(x)\n",
    "print(x.src.shape, x.trg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_network\n",
    "Encoder = my_network.Encoder\n",
    "Decoder = my_network.Decoder\n",
    "Seq2Seq = my_network.Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "# dont forget to put the model to the right device\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(1882, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(1441, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (out): Linear(in_features=512, out_features=1441, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    # <YOUR CODE HERE>\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param, -0.08, 0.08)\n",
    "        \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 8,946,337 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = TRG.vocab.stoi['<pad>']\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip, train_history=None, valid_history=None):\n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    history = []\n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg)\n",
    "        \n",
    "        #trg = [trg sent len, batch size]\n",
    "        #output = [trg sent len, batch size, output dim]\n",
    "        \n",
    "        output = output[1:].view(-1, output.shape[-1])\n",
    "        trg = trg[1:].view(-1)\n",
    "        \n",
    "        #trg = [(trg sent len - 1) * batch size]\n",
    "        #output = [(trg sent len - 1) * batch size, output dim]\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        # Let's clip the gradient\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        history.append(loss.cpu().data.numpy())\n",
    "        if (i+1)%10==0:\n",
    "            fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 8))\n",
    "\n",
    "            clear_output(True)\n",
    "            ax[0].plot(history, label='train loss')\n",
    "            ax[0].set_xlabel('Batch')\n",
    "            ax[0].set_title('Train loss')\n",
    "            if train_history is not None:\n",
    "                ax[1].plot(train_history, label='general train history')\n",
    "                ax[1].set_xlabel('Epoch')\n",
    "            if valid_history is not None:\n",
    "                ax[1].plot(valid_history, label='general valid history')\n",
    "            plt.legend()\n",
    "            \n",
    "            plt.show()\n",
    "\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    history = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "\n",
    "            output = model(src, trg, 0) #turn off teacher forcing\n",
    "\n",
    "            #trg = [trg sent len, batch size]\n",
    "            #output = [trg sent len, batch size, output dim]\n",
    "\n",
    "            output = output[1:].view(-1, output.shape[-1])\n",
    "            trg = trg[1:].view(-1)\n",
    "\n",
    "            #trg = [(trg sent len - 1) * batch size]\n",
    "            #output = [(trg sent len - 1) * batch size, output dim]\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history = []\n",
    "valid_history = []\n",
    "\n",
    "N_EPOCHS = 2\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 6m 37s\n",
      "\tTrain Loss: 6.227 | Train PPL: 506.281\n",
      "\t Val. Loss: 5.030 |  Val. PPL: 152.873\n",
      "Epoch: 02 | Time: 6m 25s\n",
      "\tTrain Loss: 5.109 | Train PPL: 165.568\n",
      "\t Val. Loss: 4.920 |  Val. PPL: 136.937\n",
      "Wall time: 13min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP, train_history, valid_history)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "    \n",
    "    train_history.append(train_loss)\n",
    "    valid_history.append(valid_loss)\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Let's take a look at our network quality__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "del utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import imp\n",
    "imp.reload(utils)\n",
    "generate_translation = utils.generate_translation\n",
    "remove_tech_tokens = utils.remove_tech_tokens\n",
    "get_text = utils.get_text\n",
    "flatten = utils.flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(test_iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: with easy access to the highway , guesthouse offers a garden with outdoor pool .\n",
      "Generated: the is is . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "\n",
      "Original: other facilities include luggage storage , laundry service and free parking space .\n",
      "Generated: the is is . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx in [1,2]:\n",
    "    src = batch.src[:, idx:idx+1]\n",
    "    trg = batch.trg[:, idx:idx+1]\n",
    "    generate_translation(src, trg, model, TRG.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "#     \"\"\" Estimates corpora-level BLEU score of model's translations given inp and reference out \"\"\"\n",
    "#     translations, _ = model.translate_lines(inp_lines, **flags)\n",
    "#     # Note: if you experience out-of-memory error, split input lines into batches and translate separately\n",
    "#     return corpus_bleu([[ref] for ref in out_lines], translations) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:15,  7.97s/it]\n"
     ]
    }
   ],
   "source": [
    "original_text = []\n",
    "generated_text = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "\n",
    "    for i, batch in tqdm.tqdm(enumerate(test_iterator)):\n",
    "\n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "\n",
    "        output = model(src, trg, 0) #turn off teacher forcing\n",
    "\n",
    "        #trg = [trg sent len, batch size]\n",
    "        #output = [trg sent len, batch size, output dim]\n",
    "\n",
    "        output = output.argmax(dim=-1)\n",
    "        \n",
    "        original_text.extend([get_text(x, TRG.vocab) for x in trg.cpu().numpy().T])\n",
    "        generated_text.extend([get_text(x, TRG.vocab) for x in output[1:].detach().cpu().numpy().T])\n",
    "\n",
    "# original_text = flatten(original_text)\n",
    "# generated_text = flatten(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\anaconda3\\lib\\site-packages\\nltk\\translate\\bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\asus\\anaconda3\\lib\\site-packages\\nltk\\translate\\bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.159730927559953e-154"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_bleu([[text] for text in original_text], generated_text) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline solution BLEU score is quite low. Try to achieve at least __18__ BLEU on the test set. \n",
    "The checkpoints are:\n",
    "\n",
    "* __18__ - minimal score to submit the homework, 30% of points\n",
    "\n",
    "* __20__ - good score, 70% of points\n",
    "\n",
    "* __25__ - excellent score, 100% of points"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "homework.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
