{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e47ca6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchtext\n",
    "from torchtext.legacy.datasets import TranslationDataset, Multi30k\n",
    "from torchtext.legacy.data import Field, BucketIterator\n",
    "\n",
    "import spacy\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'figure.figsize': (16, 12), 'font.size': 14})\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from subword_nmt.learn_bpe import learn_bpe\n",
    "from subword_nmt.apply_bpe import BPE\n",
    "from train_model import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2db3dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 40000\n",
      "Number of validation examples: 2500\n",
      "Number of testing examples: 7500\n",
      "Unique tokens in source (ru) vocabulary: 9193\n",
      "Unique tokens in target (en) vocabulary: 6714\n"
     ]
    }
   ],
   "source": [
    "# getting data\n",
    "path_to_data = '../../datasets/Machine_translation_EN_RU/data.txt'\n",
    "from data_preprocessing import get_dataset\n",
    "\n",
    "\n",
    "data, vocab = get_dataset(path_to_data)\n",
    "train_data, valid_data, test_data = data\n",
    "src_vocab, trg_vocab = vocab\n",
    "PAD_IDX = trg_vocab.stoi['<pad>']\n",
    "\n",
    "\n",
    "def _len_sort_key(x):\n",
    "    return len(x.src)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "def get_iterators(train_data=train_data, \n",
    "                  valid_data=valid_data,\n",
    "                  test_data=test_data,\n",
    "                  batch_size=512):\n",
    "\n",
    "\n",
    "    train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "        (train_data, valid_data, test_data), \n",
    "        batch_size = batch_size, \n",
    "        device = device,\n",
    "        sort_key=_len_sort_key\n",
    "    )\n",
    "    return train_iterator, valid_iterator, test_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "feb045b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from base_line_model import get_base_line_model\n",
    "baseline = get_base_line_model(len(src_vocab), len(trg_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cf043f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_loss_on_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-71bb3831ee24>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_iterator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_iterators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"baseline\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\NLP_GIT\\homeworks_22\\lab02_neural_machine_translation\\train_model.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, model_name, train_iterator, valid_iterator, optimizer, criterion, train_history, valid_history, CLIP, n_epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m                                        valid_history)\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mvalid_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_loss_on_val\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[0mend_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_loss_on_val' is not defined"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(baseline.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = get_iterators()\n",
    "train(baseline, \"baseline\", train_iterator, valid_iterator, optimizer, criterion, n_epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9d9cc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload seq_to_seq_ATTENTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ccdc3b0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\CPUAllocator.cpp:76] data. DefaultCPUAllocator: not enough memory: you tried to allocate 1237155840 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-5166d8341a6c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_iterator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_iterators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq_to_seq_ATTENTION_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"seq_to_seq_ATTENTION\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\NLP_GIT\\homeworks_22\\lab02_neural_machine_translation\\train_model.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, model_name, train_iterator, valid_iterator, optimizer, criterion, train_history, valid_history, CLIP, n_epochs)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m         train_loss = get_loss_on_train(model, \n\u001b[0m\u001b[0;32m    118\u001b[0m                                        \u001b[0mtrain_iterator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                                        \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\NLP_GIT\\homeworks_22\\lab02_neural_machine_translation\\train_model.py\u001b[0m in \u001b[0;36mget_loss_on_train\u001b[1;34m(model, iterator, optimizer, criterion, clip, train_history, valid_history)\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mtrg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1150\u001b[1;33m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[0;32m   1151\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1152\u001b[0m                                label_smoothing=self.label_smoothing)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   2844\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2845\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2846\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2847\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2848\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:76] data. DefaultCPUAllocator: not enough memory: you tried to allocate 1237155840 bytes."
     ]
    }
   ],
   "source": [
    "import seq_to_seq_ATTENTION\n",
    "\n",
    "seq_to_seq_ATTENTION_model = seq_to_seq_ATTENTION.get_model(len(src_vocab), len(trg_vocab))\n",
    "optimizer = optim.Adam(seq_to_seq_ATTENTION_model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = get_iterators()\n",
    "train(seq_to_seq_ATTENTION_model, \"seq_to_seq_ATTENTION\", train_iterator, valid_iterator, optimizer, criterion, n_epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8c77377",
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_score import get_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2f8e4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 8,951,454 trainable parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:12,  6.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 5.27175746941793e-154 \n",
      "\n",
      "Original: light hostel features free wifi throughout the property .\n",
      "Generated: the the a a a . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "\n",
      "Original: with classic , the studio comes with a tv and a kitchenette with a dining area .\n",
      "Generated: the the a a a a . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "\n",
      "Original: it offers a large outdoor pool and massage services upon request . free parking is provided .\n",
      "Generated: the the a a a . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "\n",
      "Original: resort offers a to surrounding attractions .\n",
      "Generated: the the a a a . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "\n",
      "Original: it is also less than a 10 - minute walk from the road .\n",
      "Generated: the the a a a . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "\n",
      "Original: guests at ' s garden can rent a bicycle / car to self - explore the vicinity , while massage service and airport transfers can be arranged at additional .\n",
      "Generated: the the a a a a . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "\n",
      "Original: is 46 km from da , while is 38 km from the property .\n",
      "Generated: the the a a a a . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "\n",
      "Original: offering a cosy and a rustic - style décor , apartments at feature fully equipped kitchen facilities , dining areas and living rooms with flat - screen tvs . each apartment also includes 2 bathrooms , one of them with a relaxing spa bath .\n",
      "Generated: the the a a a a . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "\n",
      "Original: bar has open and the more modern bar offers evening entertainment .\n",
      "Generated: the the a a a . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "\n",
      "Original: is a 15 - minute walk from the black sea beach .\n",
      "Generated: the the a a a . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "get_results(baseline, test_iterator, trg_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb2025ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seq_to_seq_ATTENTION\n",
    "\n",
    "seq_to_seq_ATTENTION_model = seq_to_seq_ATTENTION.get_model(9297, 6718)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8b1e866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(9297, 256)\n",
       "    (rnn): GRU(256, 512, bidirectional=True)\n",
       "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): Attention(\n",
       "      (attn): Linear(in_features=1536, out_features=512, bias=True)\n",
       "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
       "    )\n",
       "    (embedding): Embedding(6718, 256)\n",
       "    (rnn): GRU(1280, 512)\n",
       "    (fc_out): Linear(in_features=1792, out_features=6718, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_to_seq_ATTENTION_model.load_state_dict(torch.load(\"saved_models/seq_to_seq_ATTENTION.pt\", map_location=torch.device('cpu')))\n",
    "seq_to_seq_ATTENTION_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2158623d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator, valid_iterator, test_iterator = get_iterators()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8d46698",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 22,578,494 trainable parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [08:41, 34.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 2.0376431163040403\n",
      "Original: cancun bus station is 500 metres from hostel & friends , while cancun government palace is 700 metres away . the nearest airport is cancún international airport , 15 km from hostel & friends .\n",
      "Generated: a ride bbq of the - - , you access find a caves - bathroom the , , you access find a caves - minute or away , you can find a bathroom shops and , you can find a bathroom the of , you can find a bathroom the of , you access find a caves - bathroom . \n",
      "\n",
      "Original: all rooms include a tv with cable channels .\n",
      "Generated: each variety pool a 24 rooms with a . \n",
      "\n",
      "Original: saint cathedral and church are a 3 - minute walk away , and the blue mosque is a 3 - minute walk from the property .\n",
      "Generated: the offers property an dining including , a km , , , and . \n",
      "\n",
      "Original: free private parking is available on site .\n",
      "Generated: the equipped pool a the centre of the centre . \n",
      "\n",
      "Original: set within the historic core of zadar , just steps away from the seaside promenade , apartment house of peace offers air conditioning and free wifi access .\n",
      "Generated: the house is a grand and and a private to with air 4 and air 4 . \n",
      "\n",
      "Original: guests can try regional and international food in the hotel ’ s country - style restaurant .\n",
      "Generated: international a option of the metro , the hotel property a ' of the staff has . \n",
      "\n",
      "Original: the rooms of the are classically decorated and come with a 32 - inch satellite tv , a safe , and views of ' s bell tower or ' s dome .\n",
      "Generated: the is electric seating a bath and and and the - spacious tv with a . \n",
      "\n",
      "Original: some rooms have a private balcony or patio .\n",
      "Generated: the can international a few at the on - site restaurant . \n",
      "\n",
      "Original: escape theme park is a 40 - minute drive away .\n",
      "Generated: the pool a . \n",
      "\n",
      "Original: located just 400 metres from the popular bačvice beach and 700 metres from the centre of split and its unesco - protected diocletian ' s palace , apartment is air - conditioned and offers a furnished balcony .\n",
      "Generated: the air - conditioned tv with a private as with a metres from the and and metres from the metres from the metres from the metres from the metres from the metres from the metres from the metres from the metres from the metres from the metres from the metres from the metres from the metres from the metres from the metres from the metres from the and . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_results(seq_to_seq_ATTENTION_model, test_iterator, trg_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c565b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "86286382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_bleu([[\"how\"]], [[\"how\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72f2d789",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp1 = ['It', 'is', 'a', 'guide', 'to', 'action', 'which',\n",
    "        'ensures', 'that', 'the', 'military', 'always',\n",
    "        'obeys', 'the', 'commands', 'of', 'the', 'party']\n",
    "\n",
    "ref1a = ['It', 'is', 'a', 'guide', 'to', 'action', 'that',\n",
    "         'ensures', 'that', 'the', 'military', 'will', 'forever',\n",
    "         'heed', 'Party', 'commands']\n",
    "ref1b = ['It', 'is', 'the', 'guiding', 'principle', 'which',\n",
    "         'guarantees', 'the', 'military', 'forces', 'always',\n",
    "         'being', 'under', 'the', 'command', 'of', 'the', 'Party']\n",
    "ref1c = ['It', 'is', 'the', 'practical', 'guide', 'for', 'the',\n",
    "         'army', 'always', 'to', 'heed', 'the', 'directions',\n",
    "         'of', 'the', 'party']\n",
    "\n",
    "hyp2 = ['he', 'read', 'the', 'book', 'because', 'he', 'was',\n",
    "        'interested', 'in', 'world', 'history']\n",
    "ref2a = ['he', 'was', 'interested', 'in', 'world', 'history',\n",
    "         'because', 'he', 'read', 'the', 'book']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "53d304ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.18037635691578"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_references = [[ref1a]]\n",
    "hypotheses = [hyp1]\n",
    "corpus_bleu(list_of_references, hypotheses) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2aada5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
